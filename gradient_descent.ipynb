{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import sympy as sp\n",
    "from sympy import symbols, diff\n",
    "\n",
    "\n",
    "import scipy.optimize as opt\n",
    "\n",
    "def newton(fp, fpp, x0, tol, maxiter):\n",
    "    '''\n",
    "    This function locates the minima of a function f using Newtons Method\n",
    "    \n",
    "    input: first derivative of f, second derivative of f, stopping tolerance , and max itertations \n",
    "    output: returns the approximate optimizer, whether or not it converged, and number of iterations computed\n",
    "    '''\n",
    "    \n",
    "    k = 0 #tracks number of iterations \n",
    "    xk = x0 #starting point \n",
    "    xkp = xk - (fp(xk)/fpp(xk)) #Uses Newtons Method to initialize first iteration \n",
    "    converged  = False\n",
    "    \n",
    "    #iterates until stopping tolerance is reached or max num of iterations is excedded\n",
    "    while np.abs(xk - xkp) > tol and k < maxiter:  \n",
    "        xk = xkp\n",
    "        xkp = xk - (fp(xk)/fpp(xk))\n",
    "        k += 1\n",
    "        \n",
    "    if np.abs(xk - xkp) < tol:\n",
    "        converged = True\n",
    "    \n",
    "    return xk, converged, k\n",
    "    \n",
    "    pass\n",
    "\n",
    "def descent(f, df, x0, tol, maxiter):\n",
    "    '''\n",
    "    This function accepts a function f and its derivative and returns an approximate minimizer \n",
    "    using the exact method of steepest descent, the step size is chosen using a one dimensional \n",
    "    optimization method function opt.minimize_scalar()\n",
    "    \n",
    "    input: function f, derivative of f, starting point x0, stopping tolerance, and max iterations\n",
    "    output: returns the approximate optimizer, whether or not it converged, and the number of iterations \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #initialize step size using exact method of direct descent \n",
    "    f_a = lambda a : f(x0 - a*df(x0).T)\n",
    "    a = opt.minimize_scalar(f_a).x\n",
    "    k = 1 #tracks number of iterations \n",
    "    xk = x0\n",
    "    xkp = xk - a*df(xk).T\n",
    "    converged  = False\n",
    "    \n",
    "    while max(abs(df(xkp))) >= tol and k <= maxiter:\n",
    "        xk = xkp\n",
    "        f_a = lambda a : f(xk - a*df(xk).T)\n",
    "        a = opt.minimize_scalar(f_a).x\n",
    "        xkp = xk - a*df(xk).T\n",
    "        k += 1\n",
    "              \n",
    "    if max(abs(df(xkp))) < tol:\n",
    "        converged = True\n",
    "           \n",
    "    return xkp, converged, k\n",
    "\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1.4473142236328096, True, 48) -1.4473142236328096\n"
     ]
    }
   ],
   "source": [
    "#Problem 2:\n",
    "#Testing newton function where f = x**2 + sin(5*x), x0 = 0, tol = 1e-10, maxiter = 500.\n",
    "\n",
    "df = lambda x : 2*x + 5*np.cos(5*x)\n",
    "d2f = lambda x : 2 - 25*np.sin(5*x)\n",
    "#opt.newton(df, x0=0, fprime=d2f, tol=1e-10, maxiter=500)\n",
    "print(newton(df,d2f,0,1e-10,500),opt.newton(df, x0=0, fprime=d2f, tol=1e-10, maxiter=500))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9.24407773e-10, 9.24407773e-10, 9.24407773e-10]), True, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Problem 4:\n",
    "#Testing descent function on f = x**4 + y**4 + z**4, x0 = [1,1,1], tol = 1e-5, maxiter = 100.\n",
    "\n",
    "f = lambda x: x[0]**4 + x[1]**4 + x[2]**4\n",
    "df = lambda x: np.array([4*x[0]**3,4*x[1]**3,4*x[2]**3])\n",
    "x0 = np.array([1,1,1])\n",
    "\n",
    "descent(f,df,x0,1e-5,100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.99998999, 0.99997994]), True, 8019)\n"
     ]
    }
   ],
   "source": [
    "#Testing descent function on the Rosenbrock function.\n",
    "\n",
    "rosen = lambda x : (1 - x[0])**2 + 100 * (x[1] - x[0]**2)**2\n",
    "drosen = lambda x : np.array([-2*(1 - x[0]) + -200*2*x[0]*(x[1] - x[0]**2), 200*(x[1] - x[0]**2)])\n",
    "x0 = np.array([0,0])\n",
    "print(descent(rosen, drosen, x0, tol = 1e-5, maxiter = 10000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
